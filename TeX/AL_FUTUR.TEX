%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% al_futur.tex --- 
%%% Author          : blehr
%%% Created On      : Sun Mar 28 02:32:42 1993
%%% Last Modified By: blehr
%%% Last Modified On: Thu Apr  8 16:47:13 1993
%%% RCS revision    : $Revision$ $Locker$
%%% Status          : In writing....
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{{\octopus} and the Complete System}
\label{algo:future}

In this section the modifications and additions that have to be made
to {\octopus} in order to have it work in cooperation with the
complete eye-tracking system are discussed.  Problems pertaining to
non-algorithmic parts of the system, such as the camera and
illumination setups mentioned in Section~\ref{intro:problem}, are not
discussed.

\subsection{Major Line of Operation}
\label{algo:future:line}

The major line of operation for {\octopus} when integrated in the
complete eye-tracking system will be as follows: 

\begin{enumerate}
\item {\octopus} declares itself ready to start processing a new
  image by sending a ready-signal to the frame-grabber.
\item It waits until the frame-grabber signals that a new image is
  available for processing.  At the reception of this signal, the
  present time is logged in order to be able to relate the returned
  gaze direction with the registered brain activity.
\item When a dedicated timer signals that the previous 20 ms period is
  ended, processing of the new image starts and the timer is reset to
  signal the end of the next 20 ms period.
\item As soon as a final position estimate has been arrived at, the
  position of the corresponding point of focus is sent to a given port
  address of the host PC.  A signal is given that this position is
  available at the port.  The relation between position estimate and
  point of focus was given in Section~\ref{algo:future:output} above.
\item {\octopus} returns to step 1 and the process is repeated.
\end{enumerate}

Evidently, the above procedure assumes that {\octopus} always will be
able to arrive at a final position estimate in less than 20 ms.  With
the time measures presented in Section~\ref{algo:eval:test}, this
ought to be a valid assumption.  However, if measures are taken to
correct for errors due to distortions of the pupil's appearance
whenever the subject does not look straight into the camera (cf.\ 
Section~\ref{algo:eval:improve}), the computational overhead
introduced may invalidate this assumption.

\subsection{Desired Output from {\octopus}}
\label{algo:future:output}

As is clear from the preceeding sections, the value returned by the
current formulation of {\octopus} is a coordinate pair corresponding
to the estimated position of the pupil centre relative to the upper
left corner of the image.  However, this is not the coordinate pair
that is of primary interest from an experimental point of view.
Moreover, the actual point of interest is the point on the inducing
monitor (cf.\ Section~\ref{intro:motivation}) at which the subject
focuses, hereafter referred to as the {\em point of focus\/}.
Consequently, the position of the pupil in an image has to be mapped
to the point on the inducing monitor corresponding to it.

An admittedly memory consuming but time-efficient approach to
implementing this mapping is to create for the $n\times N$ image a
$N\times N$ array containing, for each possible (discrete) location of
the pupil in the image, the corresponding point of focus on the
inducing monitor.  Accordingly, when {\octopus} has arrived at a final
position estimate for a given image, the $x$ and $y$ values of this
estimate are used to index the array, and the coordinate pair thus
obtained is made available to the outside world.

An array of this type would, assuming an image resolution of
$512\times 512$, require 1MB of memory, when each coordinate pair
contained in it requires 32 byte.  This would, however, constitute no
major problem, considering today's low cost and availability of RAM
expanders.  The advantage of this approach is that, assuming an
invariant experimental setup (cf.\ the next section), the values
contained in it can be computed once and then be stored in a file
which is read anew each time {\octopus} is invoked.  Moreover, the
inherit non-linearity between the pupil position in the image and the
actual gaze angle can be compensated for without computational
overhead by incorporating the needed correction in the values
contained in the array.

\subsection{Calibrating the Experimental Setup}
\label{algo:future:calibrate}

When employing the above array to map the location of the pupil in an
image to the corresponding point of focus on the inducing monitor, it
is of vital imortance that the coordinate pairs contained in the array
actually represent the correct points of focus in the given setup.  If
this is not the case, the estimates supplied by {\octopus} are of no
value whatsoever.  Accordingly, either care has to be taken when
calibrating the experimental setup, or the values contained in the
array have to be computed anew for each experiment.

An approach to initially compute the values to be contained in the
array is to make five illuminated points appear on the inducing
monitor, and as the subject focuses on each of the points, register
the position estimates returned by {\octopus}.  Since the coordinates
on the inducing monitor of the five points are known, the relations
thus obtained can be used to compute the entire set of values for the
array.

If it can be made certain that the position of the camera relative to
the eye of the subject is exactly the same from one experiment to
another, and that this also applies to the infrared mirror between the
eye and the camera, the array thus obtained can be stored in a file.
Next time an experiment is to be made, this file is read and the array
initialized with the values contained in it.  However, if this
requirement cannot be satisfied, which is most probable to be the
case, the values contained in the array have to be computed each time
an experiment is made, and the above procedure will constitute a part
of the calibration process of the experimental setup.

\subsection{Cooperation and Correlation}
\label{algo:future:cooperate}

Evidently, the proper functioning of {\octopus} in a complete
eye-tracking system depends on its ability to work in cooperation and
correlation with other integral parts of the system.  In addition, as
pointed out in the overall problem definition in
Section~\ref{intro:problem}, an interface between the eye-tracking
system and the registering equipment of the setup has to be designed,
in order to enable the simultaneous and correlated registration of
brain activity and gaze direction.

\subsubsection{Cooperating with the Frame-Grabber}

From the above, it is evident that some sort of communication between
{\octopus} and the employed frame-grabber has to take place.  The line
of operation depicted indicates that this has to be a two-way
communication, having {\octopus} tell the frame-grabber that it is
ready to start processing a new image, as well as having the
frame-grabber tell {\octopus} that a new image is available for
processing.  In a strict sense, only the latter of these two is
necessary, since the former can be implemented by having {\octopus}
ignore all signals that a new image is available until it is ready to
start processing.  Still, it is important that the frame-grabber
signal that a new image is available, since otherwise {\octopus} might
start reading pixel values from memory locations still being written.
Also, this signal is used to log the time when the gaze direction was
recorded, and is thus of vital importance for the ability to relate it
to the registered brain activity.

Another important issue is the location of the memory to which the
digitized image is written.  If {\octopus} is to run in the CPU of the
host PC, it would be preferrable to have this be the RAM of the host
PC.  However, since most commercially available frame-grabbers have
their own storage devices, this will hardly be possible.  Moreover, it
would require transferring the entire digitized image to the main
memory of the host PC during the digitization process.  If this
transfer were to be carried out over the PC bus, its comparably low
transfer rate would make little---if any---time available for
processing the image.  An alternative solution would be to use a
dedicated parallel bus for this purpose, using DMA to access the main
memory.  

The easiest and most cost-efficient solution, though, would be the
straightforward approach; to let the frame-grabber write the digitized
images to its own storage device(s).  This, however, imposes another
problem on the setup, since {\octopus} operates by accessing indvidual
pixels of the digitized image.  If the digitized image is to be stored
on the frame-grabber board and the processing is to take place in the
CPU of the host PC, the pixel values of the image have to be accessed
over the PC bus.  Since {\octopus} operates by accessing individual
pixels of the image, this would imply initiating and closing a
dedicated transfer session for each pixel value needed, thus imposing
an unproportionally high transfer overhead, in addition to the
question of the transfer rate of the PC bus at all being able to
sustain this communication.  Again, a possible solution would be to
employ a dedicated bus for this purpose, but the transfer overhead
involved suggests that another solution be sought.

The apparantly most promising approach to the above problem would be
to purchase a frame-grabber also possessing an on-board processor
capable of running an implementation of {\octopus} within the given
time limits.  Ideally, one processor should be dedicated to digitizing
frames received from the camera, and another processor should perform
the image analysis.  In addition, the purchased board should possess
two memory banks to enable {\octopus} to access one image while the
next is being digitized.  Accordingly, the digitized frames have to be
written to the two banks in an interleaved manner.  

Presently, a Transputer-based DSP board has kindly been placed at the
group's disposal, possessing one T800 and one T200.  Attempts are
being made at having the T200 grab the frames, which at a later stage
would make it possible to have the T800 perform the image analysis.
However, the board will remain at our disposal only for a limited time
period, and its cost ($\sim$ DM18.000) suggests that another board
would have to be sought for the final implementation.  Still, the
experiences obtained with it may prove valuable when a cheaper board
has been chosen and is about to be programmed.

\subsubsection{Correlation Issues}

As pointed out in Section~\ref{intro:synch}, it is of vital importance
for the proper functioning of the complete eye-tracking system within
the framework of the Synchronization and Cognition-project that it be
possible to relate registered brain activity to a specific gaze angle.
In other words, {\octopus} has to work in correlation with the
registering equipment of the experimental setup.  As indicated above,
the interface between {\octopus} and the general setup will consist of
a port address at which {\octopus} makes the returned estimate of the
point of focus available.  Also, each time a new frame has been
digitized by the frame-grabber, it gives a signal indicating this.
Since the time the frame is made available can be approximated to
equal the time when the visual snapshot of the subject represented by
the frame was taken, this signals triggers the current time to be
logged.  When {\octopus} signals that an estimate of the point of
focus is available at the given port address, these two values---the
time of the snapshot and the estimated point of focus resulting from
the snapshot---are coupled to form a tuple.  This tuple can be made
available to the program managing the output from the registering
equipment, so that data concerning the registered brain activity at a
given time can be compared to the estimated point of focus at that
time.
