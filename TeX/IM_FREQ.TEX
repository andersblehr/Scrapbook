%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% im_freq.tex --- 
%%% Author          : blehr
%%% Created On      : Sun Mar 14 01:27:54 1993
%%% Last Modified By: blehr
%%% Last Modified On: Sun Apr 11 13:07:49 1993
%%% RCS revision    : $Revision$ $Locker$
%%% Status          : In writing....
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The Frequency Domain}
\label{image:frequency}

Another approach to digital image processing is to manipulate the {\em
  Fourier transform\/} of the image instead of the image itself.  This
is commonly referred to as analyzing the image in the {\em frequency
  domain\/}.  Below, a short introduction is given to the Fourier
transforms of one- and two-dimensional functions, starting with the
continuous case and then extending the formulation to include the
discrete case, which, in the two-dimensional case, corresponds to
digitized images.

\subsection{The Fourier Transform}
\label{image:frequency:fourier}

The formulation of the Fourier transform of a function $f$ depends on
whether the function is one- or two-dimensional, and on whether it is
a continuous or discrete function.

\subsubsection{The Continuous Fourier Transform}

The general definition of the Fourier transform is as follows.  Let
$f(x)$ be a continuous function of a real (as opposed to complex)
variable $x$.  The Fourier transform of $f(x)$, denoted ${\cal
  F}\{f(x)\}$, is then defined by the equation
\begin{equation}
\label{eq:fourier:def}
{\cal F}\{f(x)\}=F(u)=\int_{-\infty}^{\infty}f(x)e^{-j2\pi
  ux}dx\mbox{,}
\end{equation}
where $j=\sqrt{-1}$.  When $F(u)$ is known, $f(x)$ can be obtained
using the {\em inverse Fourier transform\/}, denoted ${\cal
  F}^{-1}\{F(u)\}$, and defined by the equation
\begin{equation}
\label{eq:inverse_fourier:def}
{\cal F}^{-1}\{F(u)\}=f(x)=\int_{-\infty}^{\infty}F(u)e^{j2\pi
  ux}du\mbox{.}
\end{equation}
Eqs.~(\ref{eq:fourier:def}) and~(\ref{eq:inverse_fourier:def}) are
called a {\em Fourier transform pair\/}.  The Fourier transform and
its inverse can be shown to exist if $f(x)$ is continuous and
integrable and $F(u)$ is integrable.

The Fourier transform of a real function is generally complex:
\begin{equation}
\label{eq:fourier:R+I}
F(u)=R(u)+jI(u)\mbox{,}
\end{equation}
where $R(u)$ and $I(u)$ are the real and imaginary parts of $F(u)$,
respectively.  It is often convenient to express
Eq.~(\ref{eq:fourier:R+I}) in exponential form:
\begin{equation}
  F(u)=|F(u)|e^{j\phi(u)}\mbox{,}
\end{equation}
where
\begin{equation}
\label{eq:fourier:spectrum}
|F(u)|=\sqrt{R^{2}(u)+I^{2}(u)}
\end{equation}
and
\begin{equation}
\label{eq:fourier:phase}
\phi(u)=\tan^{-1}\left[\frac{I(u)}{R(u)}\right]\mbox{.}
\end{equation}
The magnitude function $|F(u)|$ is called the {\em Fourier spectrum\/}
of $f(x)$, and $\phi(u)$ its {\em phase angle\/}.  The square of the
Fourier spectrum,
\begin{equation}
\label{eq:fourier:power}
P(u)=|F(u)|^{2}=R^{2}(u)+I^{2}(u)
\end{equation}
is called the {\em power spectrum\/} of $f(x)$.

The term frequency domain stems from the fact that the exponential
term of Eq.~(\ref{eq:fourier:def}) can be expressed in the form
\begin{equation}
  e^{-j\pi ux}=\cos 2\pi ux-j\sin 2\pi ux\mbox{,}
\end{equation}
thus indicating that $F(u)$ is composed of an infinite sum of sine and
cosine terms, the frequency of which being determined by the {\em
frequency variable\/} $u$.

The general two-dimensional Fourier transform pair is analogously
defined:
\begin{equation}
  {\cal F}\{f(x,y)\}=F(u,v)=\int_{-\infty}^{\infty}
  \int_{-\infty}^{\infty}f(x,y)e^{-j2\pi(ux+vy)}dxdy
\end{equation}
and
\begin{equation}
  {\cal F}^{-1}\{F(u,v)\}=f(x,y)=\int_{-\infty}^{\infty}
  \int_{-\infty}^{\infty}F(u,v)e^{j2\pi(ux+vy)}dudv\mbox{,}
\end{equation}
$u$ and $v$ being the frequency variables.

The Fourier spectrum, phase and power spectrum in the two-dimensional
case are defined ana-logously to
Eqs.~(\ref{eq:fourier:spectrum}),~(\ref{eq:fourier:phase}),
and~(\ref{eq:fourier:power}):
\begin{equation}
\label{eq:fourier:spectrum2}
|F(u,v)|=\sqrt{R^{2}(u,v)+I^{2}(u,v)}
\end{equation}
\begin{equation}
\label{eq:fourier:phase2}
\phi(u,v)=\tan^{-1}\left[\frac{I(u,v)}{R(u,v)}\right]
\end{equation}
and
\begin{equation}
\label{eq:fourier:power2}
P(u,v)=|F(u,v)|^{2}=R^{2}(u,v)+I^{2}(u,v)\mbox{.} 
\end{equation}

\subsubsection{The Discrete Fourier Transform}

Since we are dealing with digitized images consisting of $M\times N$
pixels having discrete gray levels, it is necessary to reformulate the
Fourier transform for the discrete case.  The principle is first
introduced for the one-dimensional case, and thereafter extended to
include the two-dimensional case.

When a continuous function $f(x)$ is discretized into a sequence
$\{f(x_{0}),f(x_{0}+\Delta x),f(x_{0}+2\Delta x),\ldots,
f(x_{0}+(N-1)\Delta x)\}$ by taking $N$ samples $\Delta x$ units
apart, its {\em discrete\/} Fourier transform is given by the
relation\footnote{For a proof of these results, see for
  instance~\cite{brigham}.}
\begin{equation}
\label{eq:fourier:discrete}
  F(u)=\frac{1}{N}\sum_{x=0}^{N-1}f(x)e^{-\frac{j2\pi ux}{N}}
\end{equation}
for $u=0,1,2,\ldots,N-1$, where $f(x)$ is given by
\begin{equation}
  f(x)=f(x_{0}+x\Delta x)\mbox{.}
\end{equation}
Analogously, the inverse discrete Fourier transform is given by
\begin{equation}
\label{eq:fourier:discrete:inverse}
  f(x)=\sum_{u=0}^{N-1}F(u)e^{\frac{j2\pi ux}{N}}
\end{equation}
for $x=0,1,2,\ldots,N-1$.

The discrete Fourier transform pair of a two-dimensional function
$f(x,y)$ whose one variable $x$ has been discretized by taking $M$
samples $\Delta x$ units apart and whose second variable $y$ has been
discretized taking $N$ samples $\Delta y$ units apart is defined
analogously to the one-dimensional case above:
\begin{equation}
  F(u,v)=\frac{1}{MN}\sum_{x=0}^{M-1}\sum_{y=0}^{N-1}f(x,y)e^{-j2\pi
    (\frac{ux}{M}+\frac{vy}{N})} 
\end{equation}
for $u=0,1,2,\ldots,M-1$, $v=0,1,2,\ldots,N-1$, and
\begin{equation}
  f(x,y)=\sum_{u=0}^{M-1}\sum_{v=0}^{N-1}F(u,v)e^{j2\pi
    (\frac{ux}{M}+\frac{vy}{N})} 
\end{equation}
for $x=0,1,2,\ldots,M-1$ and $y=0,1,2,\ldots,N-1$.

The Fourier spectrum, phase and power spectrum of the two-dimensional
discrete function are given by
Eqs.~(\ref{eq:fourier:spectrum2}),~(\ref{eq:fourier:phase2})
and~(\ref{eq:fourier:power2}), respectively.  The only difference is
that the independent variables are discrete.

\subsubsection{The Fast Fourier Transform}

When implementing the discrete Fourier transform, it is important that
the number of operations be kept as low as possible in order to
reduce computing time.  It can be shown that the formulation in
Eq.~(\ref{eq:fourier:discrete}) requires $O(N^{2})$ operations, $N$
being the number of samples used to discretize the original continuous
function.  The {\em fast Fourier transform\/} ({\fft}) is an algorithm
which, by properly decomposing Eq.~(\ref{eq:fourier:discrete}),
reduces the number of operations needed to $O(N\log_{2}N)$.  The
formulation given here is from~\cite{digim}, but is by no means a
unique formulation.  For a comprehensive discussion of a number of
formulations for the {\fft}, including this one, see~\cite{brigham}.

It will be convenient in the following discussion to express
Eq.~(\ref{eq:fourier:discrete}) in the form
\begin{equation}
\label{eq:fft}
  F(u)=\frac{1}{N}\sum_{x=0}^{N-1}f(x)W_{N}^{ux}\mbox{,}
\end{equation}
where
\begin{equation}
\label{eq:fft:W_N}
  W_{N}=e^{-\frac{j2\pi}{N}}\mbox{,}
\end{equation}
and $N=2^{n}$, $n>0$.  Based on this, $N$ can be expressed as
\begin{equation}
\label{eq:fft:N=2M}
  N=2M\mbox{.}
\end{equation}
Substitution of Eq.~(\ref{eq:fft:N=2M}) into Eq.~(\ref{eq:fft})
yields 
\begin{eqnarray}
\label{eq:fft:sep1}
  F(u) & = & \frac{1}{2M}\sum_{x=0}^{2M-1}f(x)W_{2M}^{ux}\nonumber\\
       & = & \frac{1}{2}\left\{\frac{1}{M}\sum_{x=0}^{M-1}
             f(2x)W_{2M}^{u(2x)}+
             \frac{1}{M}\sum_{x=0}^{M-1}
             f(2x+1)W_{2M}^{u(2x+1)}\right\}\mbox{.}
\end{eqnarray}
From Eq.~(\ref{eq:fft:W_N}) we have that $W_{2M}^{2ux}=W_{M}^{ux}$.
Eq.~(\ref{eq:fft:sep1}) may then be expressed as
\begin{equation}
\label{eq:fft:sep2}
  F(u)=\frac{1}{2}\left\{\frac{1}{M}\sum_{x=0}^{M-1}f(2x)W_{M}^{ux}+
  \frac{1}{M}\sum_{x=0}^{M-1}f(2x+1)W_{M}^{ux}W_{2M}^{u}\right\}\mbox{.}
\end{equation}
If we define
\begin{equation}
\label{eq:fft:F_even}
  F_{\even}(u)=\frac{1}{M}\sum_{x=0}^{M-1}f(2x)W_{M}^{ux}
\end{equation}
\begin{equation}
\label{eq:fft:F_odd}
  F_{\odd}(u)=\frac{1}{M}\sum_{x=0}^{M-1}f(2x+1)W_{M}^{ux}
\end{equation}
for $u=0,1,2,\ldots,M-1$, Eq.~(\ref{eq:fft:sep2}) becomes
\begin{equation}
\label{eq:fft:Fevenodd}
  F(u)=\frac{1}{2}\{F_{\even}(u)+F_{\odd}(u)W_{2M}^{u}\}\mbox{.}
\end{equation}
Also, since $W_{M}^{u+M}=W_{M}^{u}$ and $W_{2M}^{u+M}=-W_{2M}^{u}$, it
follows from Eqs.~(\ref{eq:fft:F_even})
through~(\ref{eq:fft:Fevenodd}) that
\begin{equation}
\label{eq:fft:doubling}
  F(u+M)=\frac{1}{2}\{F_{\even}(u)-F_{\odd}(u)W_{2M}^{u}\}\mbox{.}
\end{equation}

The essence of the {\fft} algorithm lies in the observation that the
transform of an $N$-point function can be computed by dividing the
original expression into two parts, as done in
Eqs.~(\ref{eq:fft:sep1}) and~(\ref{eq:fft:sep2}).  Note that the
interval of $u$ for which these equations are defined, $[0,M-1]$,
corresponds to the first half of the original interval $[0,N-1]$.
Computation of $F(u)$ within this interval is thus performed by
computing the two $N/2$-point transforms $F_{\even}(u)$ and
$F_{\odd}(u)$, as defined in Eqs.~(\ref{eq:fft:F_even})
and~(\ref{eq:fft:F_odd}), and then applying
Eq.~(\ref{eq:fft:Fevenodd}) to the results to form $F(u)$ for $u$ in
$[0,M-1]$.  The values of $F(u)$ for $u$ in $[M,N-1]$ follow directly
from Eq.~(\ref{eq:fft:doubling}).  Computation of $F_{\even}(u)$ and
$F_{\odd}(u)$ is carried out in the exact same manner, by dividing
each of them into two and proceeding as described above.  This process
is carried on recursively downwards until the transforms to be
computed are $1$-point transforms, which correspond to the samples
themselves.  These are then promoted upwards to form intermediate
results on all levels, until finally, on the top level, the overall
transform has been computed.  This process is referred to as {\em
  successive doubling\/}.  The name arises from the fact that a
two-point transform is computed from two one-point transforms, a
four-point transform from two two-point transforms, and so on.

The inverse Fourier transform is easily implemented using the {\fft}
algorithm described above.  To see this, consider
Eqs.~(\ref{eq:fourier:discrete})
and~(\ref{eq:fourier:discrete:inverse}), which are repeated below:
\begin{equation}
\label{eq:fourier:discrete:2}
  F(u)=\frac{1}{N}\sum_{x=0}^{N-1}f(x)e^{-\frac{j2\pi ux}{N}}
\end{equation}
\begin{equation}
\label{eq:fourier:discrete:inverse:2}
  f(x)=\sum_{u=0}^{N-1}F(u)e^{\frac{j2\pi ux}{N}}\mbox{.}
\end{equation}
Taking the complex conjugate of
Eq.~(\ref{eq:fourier:discrete:inverse:2}) and dividing both sides by
$N$ yields
\begin{equation}
\label{eq:fft:inverse}
  \frac{1}{N}f^{\ast}(x)=\frac{1}{N}\sum_{u=0}^{N-1}F^{\ast}(u,v)
  e^{-\frac{j2\pi ux}{N}}\mbox{.}
\end{equation}
The right side of Eq.~(\ref{eq:fft:inverse}) is in the form of the
forward Fourier transform in Eq.~(\ref{eq:fourier:discrete:2}).  Thus,
if $F^{\ast}(u)$ is input into an algorithm computing the forward
transform, the result will be the quantity $f^{\ast}(x)/N$.  Taking
the complex conjugate and multiplying by $N$ yields the inverse
Fourier transform $f(x)$.

As mentioned above, this algorithm performs in $O(N\log_{2}N)$ time,
the number of complex multiplications and additions being
$\frac{1}{2}N\log_{2}N$ and $N\log_{2}N$, respectively.  For a proof
of these results, see for instance~\cite{brigham} or~\cite{digim}.  

Note that this formulation is for the one-dimensional case.  The
{\fft} in the two-dimensional case is computed by applying the above
formulation on a row-to-row or column-to-column basis.
\label{pg:fft:O} The number of complex operations for applying the
{\fft} on an $N\times N$ image is thus $O(N^{2}\log_{2}N)$.  Since
each operation involves the complex exponential function, which is
normally implemented using the relation $e^{x+jy}=e^{x}\cos
y+je^{x}\sin y$, it can be concluded that the {\fft}, although
cheaper than the direct implementation of
Eq.~(\ref{eq:fourier:discrete}), still is comparably expensive.

\inserteps{convolut}{\label{fig:convolution}Graphical illustration of
  convolution.}

\subsection{The Convolution Theorem}
\label{image:frequency:convolution}

The foundation of frequency domain image processing techniques is the
{\em convolution theorem\/}.  As was the case for the Fourier
transform, the theorem is presented in two steps.  First, the general
formulation of the theorem is stated for one- and two-dimensional
continuous functions, then this formulation is extended to include the
discrete case.

\subsubsection{Convolution in the Continuous Case}

The {\em convolution\/} of two continuous one-dimensional functions
$f(x)$ and $g(x)$, denoted $f(x)\ast g(x)$, is defined by the integral
\begin{equation}
\label{eq:convolution:def}
  f(x)\ast g(x)=\int_{-\infty}^{\infty}f(\alpha)g(x-\alpha)d\alpha\mbox{,}
\end{equation}
where $\alpha$ is a dummy variable of integration.  The mechanics of
the convolution integral is not easy to visualize, so the best way is
to illustrate it graphically with a simple example
(from~\cite{digim}):

\paragraph{Example:} Consider Eq.~(\ref{eq:convolution:def}) as applied
to the two functions $f(x)$ and $g(x)$ shown in
Figs.~\ref{fig:convolution}(a) and (b), respectively.  Before the
integration can be carried out, it is necessary to form the function
$g(x-\alpha)$.  This is accomplished by mirroring $g(\alpha)$ about
the vertical axis to give $g(-\alpha)$ and then displacing this
function by $x$, as shown in Figs.~\ref{fig:convolution}(c) and (d).
Then, for all values of $x$, $f(x)$ is multiplied with $g(x-\alpha)$,
and the result (the shaded portion of Fig.~\ref{fig:convolution}(e))
is integrated from $-\infty$ to $\infty$.  Since this product is $0$
for values of $\alpha$ outside the interval $[0,x]$, $f(x)\ast g(x)$
is found to be $x/2$ for $0\leq x\leq 1$.  This corresponds to the
shaded region of Fig.~\ref{fig:convolution}(e).
Fig.~\ref{fig:convolution}(f) illustrates the same process for $1\leq
x\leq 2$.  In this case, $f(x)\ast g(x)=(1-x/2)$.  As
$f(\alpha)g(x-\alpha)$ is zero for $x<0$ and $x>2$, we have that the
convolution of $f(x)$ with $g(x)$ is given by
\begin{equation}
  f(x)\ast g(x)=\left\{\begin{array}{ll}
                         x/2   & 0\leq x\leq 1 \\
                         1-x/2 & 1\leq x\leq 2 \\
                         0     & \mbox{elsewhere,}
                       \end{array}\right.
\end{equation}
as shown in Fig.~\ref{fig:convolution}(g).\hfill$\Box$
\vspace*{0.5cm}

The importance of convolution in frequency domain analysis stems from
the fact that $f(x)\ast g(x)$ and $F(u)G(u)$ form a Fourier transform
pair.  In other words, if $f(x)$ has the Fourier transform $F(u)$ and
$g(x)$ has the Fourier transform $G(u)$, then the following relations
hold:
\begin{equation}
  {\cal F}\{f(x)\ast g(x)\}=F(u)G(u)
\end{equation}
\begin{equation}
  {\cal F}^{-1}\{F(u)G(u)\}=f(x)\ast g(x)\mbox{.}
\end{equation}
An analogous result is that convolution in the frequency domain
reduces to multiplication in the spatial domain:
\begin{equation}
  {\cal F}\{f(x)g(x)\}=F(u)\ast G(u)
\end{equation}
\begin{equation}
  {\cal F}^{-1}\{F(u)\ast G(u)\}=f(x)g(x)\mbox{.}
\end{equation}
These two results, formally stated as
\begin{equation}
  f(x)\ast g(x)\Leftrightarrow F(u)G(u)
\end{equation}
\begin{equation}
  f(x)g(x)\Leftrightarrow F(u)\ast G(u)\mbox{,}
\end{equation}
are commonly referred to as the {\em convolution theorem\/}.

The convolution of two two-dimensional functions $f(x,y)$ and $g(x,y)$
is defined analogously to Eq.~(\ref{eq:convolution:def}):
\begin{equation}
  f(x,y)\ast g(x,y)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}
  f(\alpha,\beta)g(x-\alpha,y-\beta)d\alpha d\beta\mbox{.}
\end{equation}
The two-dimensional convolution theorem is given by the relations
\begin{equation}
\label{eq:convolution:2Da}
  f(x,y)\ast g(x,y)\Leftrightarrow F(u,v)G(u,v)
\end{equation}
\begin{equation}
\label{eq:convolution:2Db}
  f(x,y)g(x,y)\Leftrightarrow F(u,v)\ast G(u,v)\mbox{.}
\end{equation}
For a graphical illustration of two-dimensional convolution,
see~\cite{digim}, p.\ 89.

\subsubsection{Convolution in the Discrete Case}

The two-dimensional {\em discrete\/} convolution is formulated by
letting $f(x,y)$ and $g(x,y)$ be discrete arrays of size $A\times B$
and $C\times D$.  For reasons elaborated upon in~\cite{brigham}, these
arrays must be assumed to be periodic with some periods $M$ and $N$ in
the $x$- and $y$-directions, respectively.  It can be
shown~(\cite{brigham}) that unless
\begin{equation}
  M\geq A+C-1
\end{equation}
\begin{equation}
  N\geq B+D-1\mbox{,}
\end{equation}
the individual periods of the convolution will overlap.  This overlap
is commonly referred to as {\em wraparound error\/}.  The periodic
sequences are formed by extending $f(x,y)$ and $g(x,y)$ as follows:
\begin{equation}
  f_{e}(x,y)=\left\{
    \begin{array}{llll}
      f(x,y) & 0\leq x\leq A-1 & \mbox{and} & 0\leq y\leq B-1 \\
      0      & A\leq x\leq M-1 & \mbox{or}  & B\leq y\leq N-1
    \end{array} \right.
\end{equation}
\begin{equation}
  g_{e}(x,y)=\left\{
    \begin{array}{llll}
      g(x,y) & 0\leq x\leq C-1 & \mbox{and} & 0\leq y\leq D-1 \\
      0      & C\leq x\leq M-1 & \mbox{or}  & D\leq y\leq N-1\mbox{.}
    \end{array} \right.
\end{equation}
With these definitions in mind, the discrete two-dimensional
convolution of $f(x,y)$ and $g(x,y)$ is expressed in terms of
$f_{e}(x,y)$ and $g_{e}(x,y)$:
\begin{equation}
\label{eq:convolution:discrete}
  f_{e}(x,y)\ast g_{e}(x,y)=\sum_{m=0}^{M-1}\sum_{n=0}^{N-1}
  f_{e}(m,n)g_{e}(x-m,y-n)
\end{equation}
for $x=0,1,2,\ldots,M-1$ and $y=0,1,2,\ldots,N-1$.

The two-dimensional convolution theorem stated in
Eqs.~(\ref{eq:convolution:2Da}) and~(\ref{eq:convolution:2Db}) also
applies to the discrete case with $u=0,1,2,\ldots,M-1$ and
$v=0,1,2,\ldots,n-1$.  

All computations involve, as indicated above, the extended functions
$f_{e}(x,y)$ and $h_{e}(x,y)$.  It is worth noting, however, that in
practice, the energy of an image tends to be concentrated around the
origin of the frequency plane.  This reduces the wraparound error due
to overlap to a non-discernible minimum, thus obliterating the need to
use $f_{e}$ and $g_{e}$ in most practical applications.

\subsubsection{Application of Convolution in Digital Image Processing}

As mentioned above, the convolution theorem forms the basis of image
processing in the frequency domain.  Let $g(x,y)$ be an image which is
the result of convolving an image $f(x,y)$ with a position-invariant
operator $h(x,y)$\footnote{A position-invariant operator is an
  operator whose result depends only on the value of $f(x,y)$ at a
  given point in the image, not on the location of the point.}:
\begin{equation}
\label{eq:convolution:operator}
  g(x,y)=h(x,y)\ast f(x,y)\mbox{.}
\end{equation}
From the convolution theorem (Eq.~(\ref{eq:convolution:2Da})) we then
have that the following relation holds in the frequency domain:
\begin{equation}
  G(u,v)=H(u,v)F(u,v)\mbox{,}
\end{equation}
where $G$, $H$ and $F$ are the Fourier transforms of $g$, $h$ and $f$,
respectively.  The function $H(u,v)$ is often referred to as the {\em
  transfer function\/} of the process.

A typical image-processing problem can be stated as
Fourier-transforming the original image $f$, yielding $F$, and then
trying to choose a transfer function $H$ such that the resulting image
\begin{equation}
  g(x,y)={\cal F}^{-1}\{H(u,v)F(u,v)\}
\end{equation}
exhibits some desired property.

\subsubsection{Spatial Masks as Convolution Masks}
\label{pg:convolutionmasks}

From a practical point of view it is often more convenient to compute
the discrete convolution of an image $f$ with an operator $h$ in the
frequency domain instead of using Eq.~(\ref{eq:convolution:discrete})
directly.  This is done by computing the Fourier transforms $F$ and
$H$ using an {\fft} algorithm, multiplying the Fourier transforms to
obtain $G$, and then applying the inverse Fourier transform to obtain
the desired image $g$.  However, in~\cite{brigham} Brigham shows that
for one-dimensional arrays, the {\fft} approach is faster only if the
number of points contributing to the operator is greater than 32.
Thus, when applying small operators, it would be convenient to be able
to perform the convolution in the spatial domain.

A useful observation in that respect is that the convolution of an
image $f$ with an operator $h$, as expressed by
Eq.~(\ref{eq:convolution:operator}), describes a spatial process
analogous to the use of masks described in
Section~\ref{image:spatial}.  In fact, the discrete convolution as
expressed by Eq.~(\ref{eq:convolution:discrete}) represents a
mathematical description of the mask-shifting process illustrated in
Fig.~\ref{fig:neighbour}.  On pp.\ 186-190 in~\cite{digim}, a method
is described for obtaining small spatial masks that approximate a
given $H(u,v)$ in a least-square-error sense.  For this reason,
spatial masks are often referred to as {\em spatial convolution
  masks\/}, and the process of applying a mask to an image is
described as {\em convolving\/} the image with the mask.

\subsection{Image Processing in the Frequency Domain}
\label{image:frequency:image}

In the Fourier transform $F$ of an image $f$ the high frequency
component is to a large extent caused by edges and other sharp
transitions in the gray levels of the image (such as noise).
Correspondingly, the low frequency component of $F$ corresponds to
continuous regions in $f$ with little or no gray level transitions.
Often, one is interested in only the high-frequency or low-frequency
components of a given image.  This can be accomplished in both cases
by attenuating the opposite end of the frequency spectrum.  This is
known as {\em highpass\/} and {\em lowpass filtering\/}, respectively.

\subsubsection{Lowpass Filtering}

Lowpass filtering is achieved by convolving the original image $f$
with an operator $h$ whose Fourier transform $H$ has the property of
either completely ({\em ideal\/} filter) or partly ({\em
  Butterworth\/} filter) filtering out the low frequency component of
$F$.  The resulting image, given by
\begin{equation}
  g(x,y)={\cal F}^{-1}\{G(u,v)\}={\cal F}^{-1}\{H(u,v)F(u,v)\}\mbox{,}
\end{equation}
then exhibits the desired properties.  Cross sections of an ideal
lowpass filter and a lowpass Butterworth filter are shown in
Fig.~\ref{fig:lowpass}, $D(u,v)$ being the distance from the point
$(u,v)$ to the origin of the frequency plane and $D_{0}$ being the
{\em cut-off frequency\/}.

\inserteps{lowpass}{\label{fig:lowpass}Cross section of an ideal
  lowpass filter (a) and a lowpass Butterworth filter (b).}

Since the high-frequency component of an image corresponds to edges
and other abrupt gray level transitions, lowpass filtering has the
effect of blurring the original image.  On the other hand, if the
image has been distorted by noise, which is also high frequency in
content, an additional effect is one of noise reduction (cf.\ 
Section~\ref{image:noise:frequency}).

\subsubsection{Highpass Filtering}

Highpass filtering is carried out analogously to lowpass filtering,
using either an ideal highpass filter or a highpass Butterworth
filter, as shown in Fig.~\ref{fig:highpass}.

\inserteps{highpass}{\label{fig:highpass}Cross section of an ideal
  highpass filter (a) and a highpass Butterworth filter (b).}

If the low-frequency content of an image is severely attenuated, the
resulting image will be one in which edges between areas of different
gray levels are predominant.  If the intent is to sharpen the edges
without loss of low-frequency information, a constant $c$ is often
added to the highpass filter transfer function, as shown in
Fig.~\ref{fig:homomorphic}, by choosing $\gamma_{L}=c$ and
$\gamma_{H}=1+c$.  This is known as {\em high frequency emphasis\/}.

\insertepswidth{homomorp}{\label{fig:homomorphic}A homomorphic filter
  transfer function.}{0.4}

High frequency emphasis is actually a special case of what is known as
{\em homomorphic filtering\/}.  Homomorphic filtering is based on an
image model saying that an image $f(x,y)$ is composed of an
{\em illumination component\/} $i(x,y)$ and a {\em reflection
  component\/} $r(x,y)$ according to the equation
\begin{equation}
  f(x,y)=i(x,y)r(x,y)\mbox{.}
\end{equation}

The illumination component of an image is generally characterized by
slow spatial variation, and is thus low frequency in content.  The
reflection, on the other hand, depends on the nature of the objects in
image and tends to vary abruptly, thus being high frequency in
content.  Assuming that $\gamma_{L}$ and $\gamma_{H}$ are chosen so
that $\gamma_{L}<1$ and $\gamma_{H}>1$, the filter function in
Fig.~\ref{fig:homomorphic} affects the low and high frequency
components of an image differently, attenuating the low frequencies
and amplifying the high frequencies.  The net result is simultaneous
dynamic range compression and contrast enhancement.  On pp.\ 192-193
in~\cite{digpic} is shown the result of applying the filter in
Fig.~\ref{fig:homomorphic} with $\gamma_{L}=0.5$ and $\gamma_{H}=2.0$
to an image with little contrast.
