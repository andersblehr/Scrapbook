%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% al_pos.tex --- 
%%% Author          : blehr
%%% Created On      : Sun Mar 28 02:27:59 1993
%%% Last Modified By: blehr
%%% Last Modified On: Sat Apr  3 19:32:36 1993
%%% RCS revision    : $Revision$ $Locker$
%%% Status          : In writing....
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Determining the Position of the Pupil}
\label{algo:pos}

The principle behind the line oriented edge detection algorithm
employed in {\octopus} was given a fairly thorough presentation in
Section~\ref{eval:approach:edge}.  Thus the focus in this section is
on the different application specific aspects of the general
algorithm.  In Section~\ref{algo:pos:operation}, an operational
description of how line oriented edge detection has been tailored to
suit the specific needs of {\octopus} is given, and in
Section~\ref{algo:pos:operators}, the gradient operators employed to
detect the pupil contour are presented.  In Section~\ref{algo:pos:O},
the number of operations required to determine the position of the
pupil is derived.

\subsection{Operational Description}
\label{algo:pos:operation}

The original formulation of line oriented edge detection, as stated in
Section~\ref{eval:approach:edge}, says that the algorithm operates by
proceeding, from the origin of operation, in different directions,
applying some edge detecting operator successively on every pixel
encountered in each direction, and, if an edge point is recognized,
registering the coordinates of this point.  By registering the
coordinates of the oppositely positioned edge points along two
perpendicular detection lines, an estimate for the position of the
pupil can be computed using the procedure illustrated in
Fig.~\ref{fig:compute}.  By taking the average of several estimates
thus computed, an improved estimate of the position is obtained.
Accordingly, as stated in the basic formulation of the {\octopus}
algorithm in Section~\ref{eval:approach:algo}, line oriented edge
detection must be applied to as high a number of line pairs as needed
to arrive at an overall estimate that does not change from one
iteration to the next.

\subsubsection{The Direct Approach}

The normal approach to tracing a line in the discrete {\em xy\/}-plane
is to choose one parameter, say $x$, as the {\em running parameter\/},
and then solve for the other parameter, in this case $y$, by using the
general slope-intercept equation $y=ax+b$.  Which parameter to choose
as the running parameter depends on the slope $a$ of the line to be
traced; if $-1\leq a\leq 1$, $x$ is used, oterwise $y$ is used; this
is to ensure the connectivity of the traced line.  Thus, in the
general case, performing line oriented edge detection along a pair of
perpendicular detection lines involves one addition and one
multiplication, respectively one subtraction and one division for each
value taken on by the running parameters $x$ and $y$, in order to
compute the location $(x_{i},y_{i})$ of the pixel on which to apply
the edge detection operator.

If $(x_{o},y_{o})$ designates the origin of operation, an approach to
implementing the general formulation above would be to displace the
origin of the image plane by a vector $[x_{o},y_{o}]^{T}$, thus making
it coincide with the origin of operation, making all detection lines
intercept at $(0,0)$ in the transposed image coordinate system.  This
would make it possible to represent each perpendicular pair of
detection lines by a single constant, namely the slope $a$ of one of
them.  The slope $a'$ of the other would be given by $a'=1/a$, and the
intercepts of both detection lines with the $y$ axis would be 0.  On
this basis, a set of detection line pairs can be maintained by
defining an array of slopes varying from 0 to $\infty$, which
corresponds to rotating the detection lines 90 degrees, thus in
principle covering all possible directions.  The actual resolution of
the directions contained in the array depends directly on its size.
An estimate of the pupil position can be computed by picking a slope
$a$ from the array, using its magnitude to determine whether $x$ or
$y$ is to be the running parameter, and then performing line oriented
edge detection along the pair of detection lines that corresponds to
$a$.  Since this procedure should be repeated until the overall
estimate no longer changes from one iteration to the next, it is
important that the number of elements in the slope array be high
enough to allow this.

There are a number of objections to this approach, despite its being a
direct implementation of Step 2 of the basic algorithm formulation in
Section~\ref{eval:approach:algo}.  For one, the computations necessary
to obtain the coordinates of each point along the detection lines
impose a computational overhead which, if possible, should be avoided.
Secondly, and most important, the slope-intercept representation of
straight lines is unable to express vertical lines, and near-vertical
lines have slopes with very high magnitudes, which, in addition to
being cumbersome to handle, decrease the computational accuracy.  Thus
it would be desirable with a technique having all the advantages of
the above approach, but without the drawbacks.

\subsubsection{Repositioning the Origin of Operation}

\insertepswidth{lines}{\label{fig:lines}Detection lines along which
  positions do not need be computed.}{0.35}

The only way to avoid the computational overhead described above, is
to reduce the number of detection lines to four.  The only four
detection lines along which no computations are necessary to obtain
the positions are the ones occupying the horizontal, vertical and two
diagonal directions, as shown in Fig.~\ref{fig:lines}.  For the
horizontal line only the $x$ parameter is varied, for the vertical
only the $y$ parameter, and for the two diagonal lines both parameters
are varied simultaneously so that either $x=y$ or $x=-y$.  

As is seen, these lines form only two pairs of perpendicular detection
lines, thus reducing the number of estimates for the pupil position to
two.  Evidently, an overall estimate computed from only two iterations
of line oriented edge detection will not suffice to satisfy the
requirement of accuracy---particularly since the procedure should
continue to iterate until the overall estimate no longer changes from
one iteration to the next.  Apparantly, however, with the given origin
of operation, no more iterations are possible without returning to the
direct approach which was deemed not satisfactory above.  There is,
however, an obvious solution to this problem: Perform the two first
iterations, obtain an overall position estimate and move the origin of
operation to this estimated position.  Thus another two iterations can
be made, resulting in an improved overall estimate.  This procedure
is, as for the above procedure, repeated until a final overall
estimate is obtained.  In fact, the only principal difference in
operation between the above technique and this, assuming that the
``quality'' of an estimate is constant with respect to the location of
the origin of operation in the image, is that with the latter, the
origin of operation has to be updated every second iteration.

Note that, when combining an intermediate position estimate with the
current overall estimate to obtain an improved overall estimate, the
current overall estimate has to be weighted according to the number of
intermediate estimates that contribute to it.  Otherwise, if the
``improved'' estimate were computed as the average of two equally
weighted image positions, one being the overall and the other being an
intermediate estimate, all the contributions made to the overall
estimate by previous intermediate estimates would be lost, and a
situation could occur in which the origin of operation is moved around
in the pupil without ever settling at a final position.  This also
applies to the direct approach above.

\subsubsection{Skipping the ``Dead Region'' about the Origin of
  Operation}

If the image quality is relatively good, that is, when choosing a
reasonable value for $T_{l}$, the extent of the pupil lake corresponds
fairly close to the actual extent of the pupil and does not extend
beyond the actual pupil contour, there is a way of reducing the time
needed for one iteration of the above procedure.  Recall how the
initial origin of operation is supplied by the swimming octopus search
algorithm.  Evidently, if $T_{s}\approx 1$ and the above requirement
of the pupil lake not extending beyond the actual pupil contour is
satisfied, an origin of operation cannot be supplied that lies closer
to the pupil contour than $r_{d}=r_{o}/\sqrt{2}$.  This is illustrated
in Fig.~\ref{fig:dead}.  The shaded region designates a fraction of
the (idealized) pupil lake, and the white circle designates a ``dead
region'' about the origin of operation inside which the probability of
locating the pupil contour is zero.  Thus, when moving outwards along
the detection lines, looking for the pupil contour, the initial
$r_{d}$ pixels of the horizontal and vertical detection lines, and the
initial $r_{d}/\sqrt{2}$ pixels along the diagonal detection lines can
be skipped, reducing the overall number of locations at which to apply
the edge detection operators.

With low-contrast images, however, like the given test images, the
``dead region'' may not be entirely ``dead''.  In other words, the
initial origin of operation may lie closer to the actual pupil contour
than $r_{d}$.  This can be attributed to the fact that $T_{s}$ has to
be chosen relatively low to ensure that some actual pupil point are
recognized as such.  Since the pupil lakes in low-contrasted images
tend to have ponds dispersed around them, some of which may lie on the
outside of the pupil boundary (cf.\ Section~\ref{algo:seek:octopus}),
there is a probability that the octopus will settle at a location at
which it has one or even two of its arms crossing the pupil boundary.
This happens when it jumps to a location at which the first
swim-criterion is satisfied by its having one (or two) of its hands in
a non-pupil pond.  Consequently, by skipping the assumed ``dead
region'', one may happen to start looking for the pupil boundary after
actually having crossed it, thus never finding it.  One solution to
this problem would be to try and choose a smaller value for $r_{d}$.
It is, however, not clear which criteria to use when choosing this
smaller value, since nothing is known about the distribution of the
non-pupil ponds surrounding the pupil lake.  Consequently, the
recommended solution, and the one I chose, since the probability of
this happening was relatively high with the given test images, is to
set $r_{d}=0$.

\insertepswidth{dead}{\label{fig:dead}The shaded region designates a
  portion of the pupil lake, and the white circle designates the
  ``dead region'' about the origin of operation, inside which the
  sought pupil contour will not be found.}{0.3}

\subsection{Edge Detection Operators}
\label{algo:pos:operators}

In the basic algorithm formulation in
Section~\ref{eval:approach:algo}, it was said that, based on the
comparison of different spatial edge detection schemes in
Fig.~\ref{fig:compare}, some sort of first-order derivative operator
would be best suited for the task of detecting the pupil contour.  Two
obvious candidates are the Sobel operators described in
Section~\ref{image:edge:gradient} and shown in Fig.~\ref{fig:sobelop}.
The result of applying these to Fig.~\ref{fig:testimages}(e) is shown
in Fig.~\ref{fig:compare}(c).  Although the pupil contour is hardly
discernable in the original image, it is clearly visible in the
processed image.  Thus, by moving along the detection lines
originating at the current origin of operation and at each pixel
appropriately thresholding the output from the Sobel operators, the
pupil contour can be detected.

\subsubsection{Characteristics of the Sobel Operators}

Before deciding to employ the Sobel operators directly as they are
depicted in Fig.~\ref{fig:sobelop}, it is necessary to examine their
characteristics and to determine if and how they can be tailored to
suit the task they are to perform.

Normally, assuming the image origin to be the upper left corner of the
image, the Sobel operators are applied to an image in two passes, one
vertical, applying the mask Fig.~\ref{fig:sobelop}(a) column by column
to every pixel in a top-down manner, and one horizontal, applying the
mask in Fig.~\ref{fig:sobelop}(b) row by row to every pixel in a left
to right manner.

\subsection{Number of Operations}
\label{algo:pos:O}

