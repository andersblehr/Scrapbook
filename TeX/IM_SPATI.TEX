%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% im_spati.tex --- 
%%% Author          : blehr
%%% Created On      : Sun Mar 14 01:24:49 1993
%%% Last Modified By: blehr
%%% Last Modified On: Sun Mar 14 02:08:02 1993
%%% RCS revision    : $Revision$ $Locker$
%%% Status          : Unknown, Use with caution!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Spatial Domain Methods}
\label{image:spatial}

The term {\em spatial domain\/} refers to the entire aggregate of
pixels making up an image.  Spatial domain methods are methods that
operate directly on these pixels.

An image in the spatial domain can be described by the two-dimensional
light-intensity function $f(x,y)$, where the value at location $(x,y)$
refers to the intensity (or {\em gray level\/}) of the image at that
point.  Image-processing functions in the spatial domain may be
expressed as
\begin{equation}
\label{eq:spatial_operator}
g(x,y)=T[f(x,y)]\mbox{,}
\end{equation}
where $g(x,y)$ is the processed image, and $T$ is an operator on the
input image $f$, defined over some neighbourhood of $(x,y)$.  In other
words, the value of $g$ at $(x,y)$ is determined by the values of $f$
within this neighbourhood.

\insertepswidth{neighbor}{\label{fig:neighbour}A $3\times 3$
  neighbourhood about a point $(x,y)$ in an image.}{0.4}

The principle approach used in defining a neighbourhood about $(x,y)$
is to use an $n\times n$ subimage of $f$, centred at $(x,y)$, as shown
in Fig.~\ref{fig:neighbour}.  Other shapes are also
possible, but square arrays are by far the most predominant, due to
their ease of implementation.  The centre of the subimage is moved
from pixel to pixel, applying the operator at each location $(x,y)$
in $f$ to yield the value of $g$ at that location.

When the size $n$ of the square neighbourhood is 1, $T$ reduces to a
gray-level {\em transformation function\/}, where the value of $g$ at
$(x,y)$ only depends on the value of $f$ at this location.  One widely
used gray-level transformation function is
\begin{equation}
\label{eq:threshold}
g(x,y)=\left\{ \begin{array}{ll} 1 & \mbox{if $f(x,y)\in Z$} \\ 0 &
\mbox{otherwise,}
                 \end{array} \right.
\end{equation}
where $Z$ is a defined set of distinct gray levels, and 0 and 1
represent the darkest and brightest allowed gray levels, respectively
(typically 0 and 255).  This is a general formulation of what is
called {\em thresholding\/}, elaborated further upon in connection
with {\em pattern recognition\/} issues in
Section~\ref{image:pattern}.

\insertepswidth{mask}{\label{fig:mask}(a) Sub-area of image. (b) A
  $3\times 3$ mask with general coefficients.}{0.5}

One of the principle approaches to the formulation in
Eq.~\ref{eq:spatial_operator} is the use of so-called {\em masks\/}.
A mask is a small two-dimensional array ($m\times n$ or, more
commonly, $n\times n$) whose elements $w_{i}$ are coefficients used to
compute $g$ at $(x,y)$.  In Fig.~\ref{fig:mask}, a $3\times 3$
sub-image centred at $(x,y)$ is shown, together with a $3\times 3$
mask with general coefficients $w_{i}$.  The value of $g$ at this
location is given by the relation
\begin{equation}
\label{eq:mask}
g(x,y)=T[f(x)]=w_{1}f(x-1,y-1)+w_{2}f(x,y-1)+\cdots+w_{9}f(x+1,y+1)\mbox{.}
\end{equation}
The coefficients $w_{i}$ are chosen to detect given properties in an
image.  For example, if all $w_{i}$ are chosen to be 1/9, the gray
level of each pixel of the resulting image $g$ would be the average of
the the gray levels of the corresponding pixel in $f$ and its 8
immediate neighbours ({\em 8-neighbours\/}).  This is known as {\em
  averaging\/}, and the effect is one of {\em blurring\/} the original
image.

Averaging is only one of several possible mask operations.  By
properly selecting the coefficients, it is possible to perform a
variety of useful image operations, among which are {\em noise
  reduction\/} (Section~\ref{image:noise}) and {\em feature
  detection\/} (Section~\ref{image:edge}).  It is worth noting,
however, that applying a mask at each pixel location in an image is a
computationally expensive task.  For example, applying the mask of
Fig.~\ref{fig:mask}(b) to a $512\times 512$ image requires nine
multiplications and eight additions at each pixel location, adding up
to a total of 2,359,296 multiplications and 2,097,152 additions.
