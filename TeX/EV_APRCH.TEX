%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ev_aprch.tex --- 
%%% Author          : blehr
%%% Created On      : Thu Mar 25 04:25:48 1993
%%% Last Modified By: blehr
%%% Last Modified On: Fri Apr  2 02:15:16 1993
%%% RCS revision    : $Revision$ $Locker$
%%% Status          : In writing....
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Chosen Approach}
\label{eval:approach}

In this section it is assumed that the images supplied by the camera
are relatively free from noise.  In other words, they will not be
subjected to a noise removing scheme prior to being input to the
algorithm.  Still, it will be aimed at making the algorithm as
insensitive as possible to the noise present in the images, mainly by
using operators on the image that introduce some kind of smoothing in
addition to performing their designated tasks.  Should it, however, at
a later stage of the project, turn out that noise removing
preprocessing of the images is necessary, it follows from the previous
section that median filtering is the computationally cheapest and also
most promising of the presented schemes.

\subsection{Rejected Approaches}
\label{eval:approach:reject}

In the previous sections, a number of techniques were discarded as
unappliccable to the given problem.  Most of the techniques were
discarded due to being to computationally expensive.  This applies to
frequency domain methods in general, being at least
$O(N^{2}\log_{2}N)$ in time; to template matching, being $O(N^{4})$ in
time; and lastly, to the Hough transform, being $O(N^{k})$ in time,
$k\geq 3$.  The other incentive to rejection was failure to serve the
putpose.  The techniques thus rejected were simple thresholding, both
as a means of segmenting out the pupil, as a criterion for inclusion
in region growing, and as a means of detecting the pupil-iris contour;
and the Laplacian operator, responding to weakly to the edges of
interest.

\subsection{Promising Aspects}
\label{eval:approach:aspect}

Many of the presented techniques displayed promising aspects which in
some way may be combined to yield a satisfactory foundation for the
algorithm to be developed.  The most promising of these aspects are
listed below:

\begin{itemize}
\item Thresholding was, as elaborated upon in
  Section~\ref{eval:eval}, discarded, both as as a means of
  segmenting out the pupil, as a criterion for inclusion in region
  growing, and as a means of detecting the pupil-iris contour.
  However, as was pointed out in Section~\ref{eval:eval:segment}, it
  can be applied to implement a {\em pixel filter\/} which can be used
  to unambigously classify a given pixel as either a pixel point or a
  non-pixel point.
\item The region growing technique, supplied with a seed point from a
  search algorithm employing some sort of pixel filter as stop
  criterion, would be able to detect the extent of the pupil, and thus
  also its centre.
\item The most promising inclusion criterion for the region growing
  approach depicted in Section~\ref{eval:eval:segment} was deemed to
  be one accepting for inclusion only those pixels {\em not\/}
  recognized as edge points.
\item By letting an edge detection procedure start from a point
  positively classified as a pupil point and then proceed in
  all directions until, in each direction, an edge is detected, the
  extent of the pupil, and thus its centre can be computed.
\item Of the presented edge detecting schemes, gradiant operators,
  examplified by the Sobel operators, turned out to give the strongest
  response to the relatively weak pupil contour in the test image in
  Fig.~\ref{fig:compare}(a).
\end{itemize}

\subsection{Satisfying the Requirement of Speed}
\label{eval:approach:speed}

As the minimum error in an eye-tracking system based on digital image
analysis is proportional to the pixel size in the digitized image, it
is desirable to employ images with as high a resolution as possible.
As pointed out in Section~\ref{intro:problem}, a resolution of
$1024\times 1024$ pixels with 256 gray levels would have been
preferred.  For reasons elaborated upon there, however, a lower
resolution of $512\times 512\times 256$ was decided upon.  Still, the
total number of pixels that the algorithm has to cope with is fairly
high: 262.144.  In contrast to this number is the maximum time of 20
ms for the algorithm to detect and locate the pupil in a given image.
From these more or less incompatible requirements it is evident that
every effort has to be put into making the algorithm as fast as
possible, without compromising the requirement of accuracy.

To solve this problem it would be beneficial if it were possible to
detect and locate the pupil without having to consider every single
pixel in the image.  The smaller the fraction of the total number of
pixels that have to be taken into consideration, the faster the
algorithm.  

\subsubsection{Region Growing?}

From the above, it is clear that one approach to reducing the number
of pixels having to be considered is to use region growing and only
include non-edge points during the growing process.  This, however,
would have to be implemented recursively, which implementation by
nature is rather expensive.  In addition, to keep track of the pixels
that have been visited and those that have not, it would be necessary
to maintain a large data structure of size similar to that of the
image.  Each time a pixel is to be tested for inclusion, this
structure has to be consulted as to whether it already {\em has\/}
been tested, which implies a large number of unnecessary comparisons.
And, perhaps most importantly, this approach requires that {\em all\/}
pixels in the pupil be tested as to whether they are to be included in
the growing region or not.  The number of pixels in the pupil is not
large compared to the total number of pixels in the image, but an even
better solution would be one with which only a subset of the pixels in
the pupil has to be considered.

\subsection{Line Oriented Edge Detection}
\label{eval:approach:edge}

\insertepswidth{compute}{\label{fig:compute}Illustration of how the
  centre of the pupil can be computed.  The circle designates the
  pupil.}{0.4}

An algorithm of which the above region growing procedure is but an
implementation is the edge detection based algorithm referred to in
the list in Section~\ref{eval:approach:aspect}, and described in
Section~\ref{eval:eval:edge}.  The basis of this algorithm is that the
pupil-iris edge can be unambigously recognized as such by letting it
be the first edge that an edge detecting algorithm encounters.  The
algorithm operates by proceeding, from a point positively classified
as a pupil point (the {\em origin of operation\/}), in different
directions, applying some edge detecting operator successively on
every pixel encountered in each direction, and, if an edge point is
recognized, registering the coordinates of this point.  Since the
pupil-iris edge can be assumed to be the first edge encountered when
moving in any direction from a point within the pupil, the points thus
detected represent the extent of the pupil.  A line passing through
the origin of operation and traversing the entire extent of the pupil
in some direction will hereafter be referred to as a {\em detection
  line\/}.  To compute the position of the centre of the pupil, it is
necessary to know the coordinates of the oppositely positioned edge
points along two perpendicular detection lines.  The procedure is
illustrated in Fig.~\ref{fig:compute}.  $(x_{o},y_{o})$ designates the
origin of operation, and $(x_{i},y_{i})$, $1\leq i\leq 4$, the edge
points detected along the two detection lines.  The centre points
$(x',y')$ and $(x'',y'')$ of the two lines with respect to the extent
of the pupil are given by the relations
$(x',y')=(\frac{1}{2}\{x_{1}+x_{4}\},\frac{1}{2}\{y_{1}+y_{4}\})$ and
$(x'',y'')=(\frac{1}{2}\{x_{2}+x_{3}\},\frac{1}{2}\{y_{2}+y_{3}\})$,
thus yielding the following expressions for the centre coordinates
$x_{c}$ and $y_{c}$ of the pupil:
\begin{equation}
\label{eq:centre:x}
  x_{c}=x'+x''-2x_{o}
\end{equation}
\begin{equation}
\label{eq:centre:y}
  y_{c}=y'+y''-2y_{o}\mbox{.}
\end{equation}
In other words, to compute an estimate of the position of the pupil on
the basis of an already known pupil point, the origin of operation
with coordinates $x_{o}$ and $y_{o}$, one needs to (1) detect the
extent of the pupil along two detection lines relative to this point,
and (2) combine the coordinates of the interception points of the
lines with the pupil-iris contour to compute $x_{c}$ and $y_{c}$,
using Eqs.~(\ref{eq:centre:x}) and~(\ref{eq:centre:y}).  This method
of detecting the extent of the pupil along detection lines will in the
following be referred to as {\em line oriented edge detection\/}.

Obviously, the estimate obtained by performing the above procedure on
only one pair of lines is not very accurate with respect to the actual
centre of the pupil.  However, by performing the procedure on several
pairs of lines and estimating the centre position to be the average of
the individual estimates thus obtained, the accuracy increases.  The
higher the number of line pairs, the higher the accuracy.

\subsection{The Algorithm: Basic Formulation}
\label{eval:approach:algo}

From the above, it is clear that of the presented algorithms and
techniques, line oriented edge detection constitutes the most
promising approach to satisfying both the requirement of speed and the
requirement of accuracy.  Accordingly, I decided to develop the
eye-tracking algorithm on this basis.  With this in mind, it is
evident that an algorithm to detect and locate the pupil in a given
image of the eye consists of two separate steps:

\begin{description}
\item[Step 1:] Apply a search strategy employing some sort of pixel
  filter to locate a point that can be unambigously classified as a
  pupil point.
\item[Step 2:] Assign the pupil point returned by the search strategy
  to the origin of operation, and use line oriented edge detection
  iteratively on different pairs of perpendicular detection lines to
  compute new estimates of the pupil position.  Repeat this process
  until the overall position estimate, given as the average of the
  individual estimates, no longer changes from one iteration to the
  next.
\end{description}

In order to minimize the probability of returning a non-pupil point as
input to Step 2, care has to be taken when chosing the search strategy
in Step 1.  Also, the fraction of the total time for the algorithm
spent searching for a pupil point has to be minimized, in order to
have as much time as possible available for Step 2, since it is not
known at the outset of the procedure how many iterations will be
needed to arrive at a final estimate.  In addition, a reasonable
choice has to be made as to the edge detection operator(s) to be
employed in Step 2.  From the list of promising aspects given in
Section~\ref{eval:approach:aspect}, it is clear that some sort of
first-order gradient operator would be best suited for this task,
considering the superior response of the Sobel-operators to the
relatively weak pupil-iris contour of the test image in
Fig.~\ref{fig:compare}(a).  It would be desirable, however, to modify
these operators in order to maximize this response.

In the next chapter, both the search strategy and the design of a
suitable edge detection operator are given thorough treatment.
